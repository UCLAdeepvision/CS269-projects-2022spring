---
layout: post
comments: true
title: VQPy
author: Pengzhan Zhao, Shi Liu
date: 2022-04-24
---


> Video analytics has been gaining popularity in recent years, due to easier production of videos as well as development in computer vision algorithms and computing hardware. Traditional video analytics pipelines require developers to spend a lot of time on model optimizations, and can be difficult to reuse. Efforts such as SQL-like languages have tried to approach this problem, but only solved part of it, due to restrictions such as limited expressiveness. We propose to implement a Python dialect called VQPy, as an attempt to make video queries easier even for people with no CV-related knowledge, with its familiar programming interface and powerful object-oriented programming model.

<!--more-->
{: class="table-of-content"}
* TOC
{:toc}

## Introduction

Video analytics applications have been ubiquitous nowadays. Millions of cameras are recording around the world, and diverse analytics programs are running in the background to achieve different functionalities. For example, speeding vehicles can be automatically detected from road surveillance videos, and the administration staff can send speeding tickets to vehicle owners based on the number badge; fall detection can recognize people potentially falling, so medical professionals can take earliest actions to prevent injuries [1]; also, train stations and airports can utilize video analytics to find unattended luggages for travellers [2].

A video analytics appllication is usually a compound process, including several different tasks organized in a certain order. Take speeding detection as example, it needs object detection to recognize vehicles and badges, uses object tracking to track speed of the vehicles, and utilize text recognition to identify badge numbers based on badge images. The good news is, for each procedure, we already have lots of models to use, such as R-CNN and YOLO for object detection, ByteTrack and TransMOT for object tracking, and classification models like CNNs for text recognition. However, which models to use for each task is not obvious, given the diverse charracteristics of data sets and goals of the user. Also, each model needs to be carefully trained and hyper-parameter needs to be tuned to achieve the best results. How to connect the models and how to transfer data between different models are also critical questions to answer. All problems mentioned above make the implementation of a video analytics application time-consuming and require expert knowledge.

Besides difficulties of implementation, video analytics applications are also faced with challenges when it comes to reusability. Let us see that now you have already implemented a video analytics pipeline, which can find all speeding trucks in white. What if now we want to have a new pipeline, whose goal is not a subset of that of our current pipeline, such as all speeding vehicles and all vehicles higher than 13ft in blue? If not carefully designed, modules in the existing pipeline can be tightly coupled, making reuse of it require intrusive modifications, further increasing time taken to build different queries.

There have been efforts trying to solve the problems, among which SQL-like languages for video analytics have gone the furthest. Take Blazelt [3] as an example, it treats camera framces as relation tables, and allows users to use SQL-like syntax to query frames which satisfy certain conditions. Examples of queries with VQPy are shown below in Figure 1. It comes with two major benefits: First, it supports some degree of modularity and reusability. Complex queries can be constructed with simple queries. Also, it relieves the burden of users to understand the implementation details. Instead, the user simply declare its goal. All procedures to select and generate the model pipeline is done by the SQL executor. Various optimizations can be made in the background for optimal performance. However, SQL-like languages still come with a major drawback: Its expressiveness is limited. When these languages treats different frames in a video as different records in a relation table, it is easy to query information on each frame, but is much harder to express queries which needs information from different frames, such as tracking an object.

![]({{ '/assets/images/team15/blazelt.png' | relative_url }})
{: style="width: 800px; max-width: 100%;"}
*Figure 1. Examples of Video Queries with Blazelt.*

To push the idea of video query language even further for a more complete expressiveness and ease of use, we purpose a new video query language, named VQPy. It is a Python dialect, implemented directly upon the standard Python, giving it broader expressiveness; Python is an object-oriented language, which means complex queries can be composed by simpler queries with class inheritance intuitively. Also, VQPy is designed as an high-level language, which means the application logic, i.e., what query to make, is separated from the underlying model implementation, just like the SQL-like languages.

An overview of a video query workflow with VQPy is shown below in Figure 2: First, user declare its goal with the query. Here the user wants to find all cars whose speed exceeds 75 in a set of frames. Then, VQPy will automatically generate logics regarding model selection and training. We also give users the option to state hints on the model information if they want to. The application logic code and the model logic code are fed into VQPy compiler, which generates the execution plan for the query.

![]({{ '/assets/images/team15/vqpy-overview.jpg' | relative_url }})
{: style="width: 800px; max-width: 100%;"}
*Figure 2. An Overview of Video Query Workflow with VQPy.*

With the power of VQPy, more complex features can be considered, such as queries upon multiple camera views, as well as queries on streaming data. We will start from simple occasions where VQPy can be used to make video queries easy for end users first, and expand the scope of the project as time permits.

## Language Design

We treat video analytics queries as user-defined functions, scanning through a sequence (or multiple sequences) of frames. Different from existing SQL-like language, such as Blazelt, the user-defined function in VQPy can be stateful, which means it can carry historical information like trajectories of objects. Users will use VQPy, as the language for these functions.

```python
class Query:
  def __call__(frame: Frame) -> Any: ...
```

VQPy is designed to be as close to Python. Instead of implementing the query imperatively, VQPy allows users to declare sub-tasks in queries. Specifically, users can use declared "abstract functions" with only type information and leave its definition to the built-in library and self-defined external libraries in a standardized format. 

For example, we have a query to count the number of cars. User can declare two abstract functions: 1) Object detection: `Frame::objs(frame: Frame) -> List[VObj]`; 2) classification `Car::isintance(obj: VObj) -> bool`, where a `VObj` stores encapsulated information of a video object, like bounding box. These two tasks should be handled by an external machine learning model, which consists of complex tensor computation, but when developing an analytics query, users should directly use it without considering any low-level details. To make a normal python function become an abstract function, users can use the `@model` decorator.

```python
class Frame:
  @model
  def objs(self: Frame) -> List[VObj]: ...

class Car(VObj):
  @model
  @staticmethod
  def isinstance(obj: VObj) -> bool: ...

class CountCarQuery(Query):
  def __call__(frame: Frame) -> int:
    results = 0
    for obj in frame.objs():
      if Car.isinstance(obj):
        results += 1
    return results
```

VQPy Compiler will take this snippet of code, to associate all model functions with concrete definitions, like pre-trained machine learning models. Some models can finish the tasks of multiple abstract functions. In this example, object detection models can usually give both the bounding box of objects and their classes.

The previous example only takes per-frame properties into consideration. VQPy also supports cross-frame properties. Use the query of showing the plates of speeding cars as an example. Here, we use the difference between center of two consecutive bounding boxes as speed. To get speed, we need to store properties in history. To achieve this, VQPy provides `@history` decorator.

```python
class Car(VObj):
  @history
  @model
  @property
  def coordinate(self: Car) -> Vector: ...

  @model
  @property
  def plate(self: Car) -> str: ...

  @property
  def speed(self: Car) -> Vector:
    return self.coordinate.state[-1] - self.coordinate.state[-2]

class CountSpeedingCarQuery(Query):
  def __call__(frame: Frame) -> List[str]:
    results = []
    for obj in frame.objs():
      if Car.isinstance(obj) and obj.speed.abs() > 75:
        results.append(obj.plate)
    return results
```

To maintain historical properties, it is required to identify the same video across frames. It implicitly requires a function `VObj::__eq__(self: VObj, other: VObj) -> bool`, which can determine whether two video objects are the same. This can be achieved by object tracking models.

## Current Progress

We have finalized the language design and written example queries using this language. We have developed and successfully run two queries - speeding ticket and untagged baggage using the traditional way by connecting models using pure Python.
TODO(Pengzhan)

## References

1. Rougier, C., Meunier, J., St-Arnaud, A., & Rousseau, J. (2011). Robust video surveillance for fall detection based on human shape deformation. IEEE Transactions on circuits and systems for video Technology, 21(5), 611-622.
2. Unattended Baggage Detection Using Deep Neural Networks in Intel® Architecture, https://www.intel.com/content/www/us/en/artificial-intelligence/solutions/unattended-baggage-detection-using-deep-neural-networks.html
3. Daniel Kang, Peter Bailis, and Matei Zaharia. 2019. BlazeIt: optimizing declarative aggregation and limit queries for neural network-based video analytics. Proc. VLDB Endow. 13, 4 (December 2019), 533–546. DOI:https://doi.org/10.14778/3372716.3372725
